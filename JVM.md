##  JVM运行时数据区

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/8A544525-1C07-41DE-AA10-72B9DBE17FF3-1608261656635.png)

> 如上图所示，JVM内存分为**线程共享**的堆、方法区和**线程私有**的本地方法栈、虚拟机栈、程序计数器
>
> **程序计数器**负责记录当前线程所执行的字节码的行号，字节码解释器工作时通过改变计数器的值来选取下一条执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖程序计数器来完成
>
> **虚拟机栈**描述的是Java方法执行的线程内存模型，其生命周期与线程相同：每个方法被执行的时候，Java虚拟机都会创建一个栈帧，用于存储局部变量表，操作数栈，动态链接，方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈入栈到出栈的过程。局部变量表存放了编译器可知的各种Java虚拟机基本数据类型、对象引用。如果线程请求的栈深度大于虚拟机所允许的深度，会抛出StackOverflowError异常；如果Java虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常。
>
> **本地方法栈**和虚拟机栈作用类似，区别只是本地方法栈为虚拟机使用到的Native方法服务。
>
> **堆**是虚拟机所管理的最大一块内存，Java堆被所有线程共享，堆的唯一目的就是存放对象实例。通过参数-Xmx和-Xms设置堆内存的最大值和最小值，当堆内存无法无法完成实例分配，并且无法扩展时，Java虚拟机会抛出OutOfMemoryError异常。
>
> **方法区**和堆一样，是各个线程共享的内存区域，用于存储**已被虚拟机加载**的类型信息、常量、静态变量、即时编译器编译后的代码等，当方法区无法满足新的内存分配需要时，会抛出OutOfMemoryError异常。
>
> **运行时常量池**是方法区的一部分，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池。
>
> **直接内存**不是虚拟机运行时数据区的一部分，NIO引入了一种基于Channel与Buffer的I/O方式，可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DriectByteBuffer对象作为这块内存的引用进行操作。这种方法能显著提升性能，因为避免了在Java堆和Native堆中来回复制数据。本机直接内存的分配不会受到Java堆大小的限制，但是会受到本机总内存大小以及处理器寻址空间的限制，一般服务器管理员配置虚拟机参数时，会根据实际内存去设置-Xmx等参数，但经常忽略掉直接内存，导致各个内存区域总和超过物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。



##  Java内存模型

Java内存模型(Java Memory Model，简称JMM) 描述的是一组规则，通过这组规则来决定一个线程对共享变量的写入何时对另一个线程可见，JMM是围绕着程序执行的原子性、可见性、有序性展开的。由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其分配一个虚拟机栈（工作内存），用于存储线程私有的数据，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存中拷贝到线程的工作内存，然后对变量进行操作，操作完成后再将变量写到主内存，不能直接操作主内存中的变量，工作内存存储着主内存中变量的副本拷贝，工作内存是每个线程的私有数据区域，因此不同的线程无法访问对方的工作内存，线程间的通信必须通过主内存来完成，其简要访问过程如下图

![20170608221857890](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/20170608221857890.png)

JMM与Java运行时数据区是不同层次的概念划分，JMM描述的是一组规则，并不实际存在，JMM通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式，JMM是围绕原子性、有序性、可见性展开的。关于JMM中的主内存和工作内存说明如下：

> - 主内存
>
>   主要存储的是Java实例对象，所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量还是方法中的本地变量（局部变量），还存放了共享的类信息、常量、静态变量。
>
> - 工作内存
>
>   主要存储当前方法所有的本地变量信息（主内存中的变量副本拷贝），每个线程只能访问自己的工作内存，即线程中的本地变量对其他线程是不可见的，即使两个线程执行的是同一段代码，也会在各自的工作内存创建属于当前线程的本地变量。

根据虚拟机规范，对于一个实例对象中的成员方法而言，如果方法中包含基本数据类型变量（boolean、byte、short、int、double、long、float），将直接存储在工作内存的栈帧结构中，如果局部变量是引用类型，那么该变量的引用会保存在工作内存的栈帧中，而对象实例会存储在主内存（堆）中。但对于实例对象的成员变量而言，不论是基本类型还是引用类型，都会存储到主内存中。静态变量及类本身相关信息会存储到主内存的方法区中。如果两个线程同时调用了同一个对象的同一个方法，那么两条线程会将要操作的数据拷贝一份到自己的工作内存中，执行完成后才刷新到主内存，如下图所示

![20170609093435508](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/20170609093435508-1608277173604.png)

### Java内存模型的承诺

JMM定义了一组规则，通过这组规则确定一个线程对共享变量的写入何时对其他线程可见，JMM围绕着程序执行的原子性、有序性、可见性展开

> - 原子性
>
>   原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个原子操作一旦开始就不会被其他线程打断，例如一个静态变量int x，两个线程同时对其赋值，线程A赋值为1，线程B赋值为2，不管线程如何运行，最终x的值要么是1，要么是2，线程A和线程B间的操作是没有干扰的，这就是原子性。
>
> - 有序性
>
>   有序性是指对于单线程的执行代码，我们认为代码的执行是按顺序执行的，但对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现重排现象，重排后的指令与原指令顺序未必一致。在Java程序中，在本线程内的所有操作都视为有序行为，多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的。前半句指的是单线程内保证串行语义执行的一致性，后半句指的是指令重排现象和工作内存与主内存同步延迟现象。
>
> - 可见性
>
>   可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值。对于单线程程序而言，可见性是不存在的，因为我们在任何一个操作中修改了某个变量的值，后续的操作中都能读取到这个变量值。但在多线程环境中，由于线程对共享变量的操作都是在工作内存中进行，完成后才写回到主内存中，这就可能存在一个线程A修改了共享变量的值，还未写回到主内存时，另一个线程B又对主内存中同一个共享变量进行操作，此时线程A修改后的值对线程B不可见。这种工作内存与主内存同步延迟现象导致了可见性问题，另外指令重排以及编译器优化也可能导致可见性问题。

### 指令重排

计算机在执行程序时，为了提高性能，编译器和处理器常常对指令做重排，一般有以下三种情况

> - 编译器优化的重排
>
>   编译器在不改变单线程程序语义的情况下，可以重新安排语句的执行顺序，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的
>
> - 指令并行的重排
>
>   现代处理器采用了指令集并行技术来讲多条指令重叠执行，如果不存在数据依赖性（即后一个执行的语句不依赖前面执行语句的结果），处理器可以改变语句对应的机器指令的执行顺序
>
> - 内存系统的重排
>
>   由于处理器使用缓存和读写缓存区，这使得加载（load）和存储（store）操作看上去可能是乱序执行，因为三级缓存的存在，导致内存与缓存的数据同步存在时间差

其中编译器优化的重排属于编译期重排，指令并行重排和内存系统重排属于处理器重排，在多线程环境中，这些重排优化可能会导致程序出现内存可见性问题。

### JMM中的happens-before原则

JMM内存模型提供了happens-before原则来辅助保证程序执行的原子性、可见性、有序性，是判断数据是否存在竞争、线程是否安全的依据，happens-before原则内容如下

> - 程序顺序原则：即在一个线程内必须保证语义串行性，也就是说代码按照顺序执行
> - 锁规则：解锁操作必然发生在后续的同一个锁的加锁之前，也就是说如果对于同一个锁解锁后再加锁，那么加锁的动作必然发生在解锁动作之后（同一个锁）
> - volatile规则：volatile变量的写，先发生于读，这保证了volatile变量的可见性。volatile变量在每次被线程访问时，都强迫从主内存中读取该变量的值，而当该变量发生变化时，又强制将最新的值刷新到主内存，任何时刻，不同的线程总是能够看到该变量的最新值
> - 线程启动原则：线程的start方法先于它的每一个动作，即如果线程A在执行线程B的start方法之前修改共享变量的值，那么当线程B执行start方法时，线程A对共享变量的修改对线程B可见
> - 传递性：A先于B，B先于C，那么A先于C
> - 线程终止规则：线程的所有操作先于线程的终结，Thread.join方法的作用是等待当前执行的线程终止。假设在线程B终止之前，修改了共享变量，线程A从线程B的join方法成功返回后，线程B对共享变量的修改对线程A可见
> - 线程终端规则：对线程interrupt方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted方法检测线程是否中断
> - 对象终结规则：对象的构造函数执行，结束先于finalize方法

### volatile

volatile是Java虚拟机提供的轻量级的同步机制，有以下两个作用

> - 保证被volatile修饰的共享变量对所有线程可见，即一个线程修改了一个被volatile修饰共享变量的值，新值可以立即被其他线程读取到
> - 禁止指令重排序

#### volatile的可见性

尽管对 volatile变量的写操作总是能立即反应到其他线程中，但是对于volatile变量运算操作在多线程环境下并不保证线程安全，如下

```java
public class VolatileVisibility {
    public static volatile int i =0;

    public static void increase(){
        i++;
    }
}
```

如上代码所示，i变量的任何改变都会立即被其他线程感知，但是如果多个线程同时调用increase方法，就会出现线程安全问题，因为i++操作不具备原子性，该操作是先读取值，然后写回一个新值，分两步完成。如果第二个线程在第一个线程读取旧值和写回新值期间读取的i的值，那么第二个线程就会与第一个线程看到同一个值，并且执行相同的加1操作，这就导致了线程不安全。因为对于increase方法必须使用synchronized修饰，以保证线程安全。

当volatile变量执行的是原子操作时，可以保证线程安全，如下代码所示

```java
public class VolatileSafe {

    volatile boolean close;

    public void close(){
        close=true;
    }

    public void doWork(){
        while (!close){
            System.out.println("safe....");
        }
    }
}
```

由于对close的修改属于原子操作，因此可以通过volatile修饰close，使该变量对其他线程可见。

#### volatile原理

当写一个volatile变量时，JMM会把该线程对应的工作内存的共享变量值刷新到主内存中，当读取一个volatile变量值，JMM会把线程中对应的工作内存置为无效，强制从主内存读取共享变量。其内存语义实现是通过**内存屏障**

#### 内存屏障

内存屏障又称内存栅栏，是一个CPU指令，有如下两个作用

> - 保证特定操作的执行顺序
> - 保证某些变量的可见性（利用该特性实现volatile的可见性）

如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另一个作用是强制刷出各种CPU的缓存数据，因此任何CPU的线程都能读取到这些数据的最新版本。volatile正式通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。

#### 禁止重排典型示例

```java
public class DoubleCheckLock {
    private static DoubleCheckLock instance;
    private DoubleCheckLock(){}
    public static DoubleCheckLock getInstance(){
        //第一次检测
        if (instance==null){
            //同步
            synchronized (DoubleCheckLock.class){
                if (instance == null){
                    //多线程环境下可能会出现问题的地方
                    instance = new DoubleCheckLock();
                }
            }
        }
        return instance;
    }
}
```

上述代码是一个典型的单例的双重检测的代码，这段代码在单线程下没有问题，但是在多线程环境下会出现线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化，instance = new DoubleCheckLock()可以分为三步完成

```java
memory = allocate(); //1.分配对象内存空间
instance(memory);    //2.初始化对象
instance = memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null
```

由于步骤2和步骤3之间没有前后依赖，重排后的执行结果在单线程中并没有改变，因此可能会出现指令重排，如下

```java
memory = allocate(); //1.分配对象内存空间
instance = memory;   //3.设置instance指向刚分配的内存地址，此时instance！=null，但是对象还没有初始化完成！
instance(memory);    //2.初始化对象
```

所以当一个线程访问instance不为null时，instance实例可能并未完成初始化，也就导致了线程安全问题。此处用volatile修饰instance变量即可禁止指令重排。



## JVM垃圾回收

#### 对象存活的判定

##### 引用计数算法

==主流Java虚拟机都没有使用引用计数算法==

在对象中添加一个引用计数器，每当有一个地方引用该对象时，计数器值加一，当引用失效时，计数器值减一，任何时刻计数器值为零的对象就是不可能再被使用的。引用计数算法原理简单，判定效率也很高，但需要配合大量额外处理才能正确工作。比如单纯的引用计数很难解决对象之间的相互循环引用问题。

##### 可达性分析算法

==Java的内存管理子系统，是通过可达性分析算法来判定对象是否存活==

可达性分析算法的根本思路是通过一系列称为"GC Roots"的根对象作为起始节点集，从这些节点开始，根据引用关系向下搜索，搜索过程走过的路径称为引用链，如果某个对象到GC Roots间没有任何引用链，或者用图论的话来说就是从GC Roots到这个对象不可达时，则证明此对象是不可能再被使用的。

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/844F8AD6-CC6F-4D0D-93DA-310D44EF2AEF.png)

如上图所示，object5、object6、object7虽然相互之间有引用，但和GC Roots之间没有引用链，因此这些对象会被判定为可回收的对象

在Java技术体系中，固定可作为GC Roots的对象包括以下几种：

- 在虚拟机栈（栈帧中的本地变量表）中引用的对象，例如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等
- 在方法区中类静态属性引用的对象，例如Java类的引用类型静态变量
- 在方法区中常量引用的对象，例如字符串常量池中的引用
- 在本地方法栈中JNI引用的对象
- JVM内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（如NullPointException、OutOfMemoryError）等，还有系统类加载器
- 所有被同步锁持有的对象
- 反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等

除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域的不同，还可以有其他对象临时性加入，共同构成完整GC Roots集合。

#### 垃圾收集算法

##### 标记-清除算法

算法分为标记和清除两个阶段，标记出所有需要回收的对象，在标记完成后，统一回收掉所有被标记的对象，也可以反过来，标记存活的对象，回收所有未被标记的对象。标记过程就是对象存活判定过程。

该算法有以下缺点：

1. 执行效率不稳定，如果Java堆中包含大量对象，而且其中大部分对象需要被回收，这是必须进行大量标记清除的动作，导致标记和清除两个过程的执行效率都随对象数量增加而降低。

2. 内存空间的碎片化问题，标记、清除之后会产生大量不连续的内存碎片，空间碎片太多会导致分配较大对象时无法找到足够的连续内存而不得不提前触发另一次垃圾回收动作。

   ![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/3310D8FC-8885-4673-BCDB-4F90F101D476.png)

##### 标记-复制算法

将新生代分为一块较大的Eden空间和两块较小的Survivor空间，每次分配内存只使用Eden和其中一块Survivor空间。发生垃圾回收时，将Eden和Survivor中仍然存活的对象一次性复制到另外一块Survivor空间，然后直接清理掉Eden和已用过的那块Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也即每次新生代中可用内存空间为整个新生代容量的90%。由于无法保证每次回收都只有不多于10%的对象存活，因此当Survivor空间不足以容纳一次Minor GC之后存活的对象时，就需要依赖其他内存区域（一般是老年代）进行分配担保。==标记-复制算法可以很好地解决标记-清楚算法导致的内存碎片化问题==。

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/31B2C8F9-B21A-474E-8A02-328ECE244770.png)

##### 标记-整理算法

标记-复制算法在对象存活率较高时需要进行大量的复制操作，效率将会降低。更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象100%存活的极端情况，因此老年代一般不能直接选用这种算法。

标记-整理算法是针对老年代对象的存亡特征提出的，其标记过程与标记-清除相同，但后续步骤不是直接对可回收对象进行清理，而是让所有的存活对象都向内存空间一端移动，然后直接清理掉边界之外的内存，标记-整理算法示意图如下图所示：

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/ECDB8BD5-CDD9-4923-90B9-C030BC7B277D.png)

标记-整理和标记-清除的本质差异在于前者是一种移动式的回收算法，而后者是非移动式的。老年代这种每次回收都有大量存活区域，每次移动对象并更新所有引用这些对象的地方必须全程暂停用于应用程序才能进行（stop the world）。

#### HotSpot算法细节实现

##### 记忆集与卡表

为解决对象跨代引用所带来的问题，垃圾收集器建立了名为记忆集的数据结构，记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构。

卡表是目前最常用的一种记忆集实现形式，卡表的每个记录精确到一块内存区域，该区域内有对象含有跨代指针。卡表最简单的形式可以只是一个字节数组，而HotSpot虚拟机也是如此实现的。以下这行代码是HotSpot默认的卡表标记逻辑：

`000                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             CARD_TABLE[this address >> 9] = 0`

字节数组CARD_TABLE中每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称为"卡页"。卡页大小大师2的N次方的字节数，通过上面代码可以看出HotSpot使用的卡页是2的9次方，即512字节。一个卡页的内存中通常包含不止一个对象，只要卡页内有一个对象的字段存在跨代引用，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏，没有则标识为0.在垃圾收集发生时，只要筛选出卡表变脏的元素，就能得出哪些卡页内存块中包含跨代指针，把他们加入GC Roots一并扫描。

##### 写屏障

HotSpot虚拟机通过写屏障技术维护卡表状态，写屏障可以看做在虚拟机层面对"引用类型字段复制"这个动作的AOP切面，供程序执行额外的动作，也就是说赋值的前后都在写屏障的覆盖范围内。在赋值前部分的写屏障称为写前屏障，在赋值后的屏障称为写后屏障。下面这段代码是更新卡表状态的简化逻辑：

```c
void oop_field_store(oop* field, oop new_value) {
	// 引用字段赋值操作
	*field = new_value;
	// 写后屏障，在这里完成卡表状态更新
	post_write_barrier(field, new_value);
}
```

应用写屏障后，虚拟机会为所有赋值操作生成相应的指令，一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生额外的开销。

#### 经典垃圾收集器

##### Serial收集器

Serial收集器是一个单线程收集器，Serial收集器进行垃圾回收时，必须暂停其他所有工作线程。其运行过程如下图所示，新生代使用Serial，老年代使用Serial-Old

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/EFEA2475-D93B-41A0-B99D-CF85D5A8C340.png)

迄今为止，Serial收集器仍然是HotSpot虚拟机运行在客户端模式下的默认新生代收集器，其优点是简单、高效，对于内存资源受限的场景，它是所有收集器里额外内存消耗最少的。在用户桌面的应用场景和微服务应用场景，新生代内存一般只有几百兆，垃圾收集的停顿时间可以控制在几十到上百毫秒，只要不是频繁发生垃圾收集，这点停顿时间不会太过影响用户体验。所以，Serail收集器对于运行在客户端模式下的虚拟机是一个很好的选择。

##### ParNew收集器

ParNew实质上是Serial收集器的多线程并行版本，ParNew/Serial Old收集器运行过程如下图所示

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/E48052C9-D1B3-43DB-AB21-5CB111E37949.png)

##### CMS收集器

> CMS收集器是一种以获取最短回收停顿时间为目标的收集器。一般运行在服务端的Java应用通常关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来更好的体验。

CMS是基于标记-清除算法实现的，其垃圾回收流程分为以下四个步骤：

1. 初始标记(CMS initial mark) - 标记GC Roots能直接关联到的对象，速度很快
2. 并发标记(CMS concurrent mark) - 从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时很长但是不需要停顿用户线程，可以与垃圾收集线程并发执行
3. 重新标记(CMS remark) - 修正并发标记期间，因用户程序继续运行而导致标记发生变动的部分对象的标记记录，这个阶段的停顿时间通常比初始标记阶段更长，但远比并发标记阶段耗时少
4. 并发清除(CMS concurrent sweep) - 清理删除掉标记阶段判定已死亡的对象，由于不需要移动存活对象，所以这个阶段可以和用户线程并发执行

其中初始标记、重新标记两个步骤需要"Stop the world"。

由于在整个过程中耗时最长的并发标记和并发清除阶段中，用户线程可以和垃圾收集线程并发执行，所以从总体上来说，CMS收集器的内存回收过程是与用户线程并发执行的。从下图可以看出CMS收集器的运作步骤中并发和需要停顿的阶段：

![img](../../../%25E7%259F%25A5%25E8%25AF%2586%25E7%25AE%25A1%25E7%2590%2586/assets/6A1E690E-137F-4DE2-B923-7E86150F8D28.png)

CMS是一款优秀的垃圾收集器，但也存在如下缺点：

1. CMS收集器对处理器资源敏感，在并发阶段，虽然不会导致用户线程停顿，但却会因为占用了一部分线程而导致应用程序变慢，降低总吞吐量。CMS默认启动的回收线程数是（处理器核心数量+3）/4。这就意味着当处理器核心数量不足4个时，CMS对用户程序的影响就可能变得很大。
2. CMS收集器无法处理浮动垃圾，有可能出现"Con-current mode failure"失败进而导致另一次Full GC的产生。在CMS的并发标记和并发清理阶段，用户线程还在继续运行，自然会伴随有新的垃圾对象的产生，但这一部分垃圾对象是出现在标记过程结束之后，CMS无法在本次收集中处理它们，只能等待下次垃圾收集时回收，这一部分垃圾就称为浮动垃圾。另外由于在垃圾收集阶段用户线程还在继续工作，因此需要预留足够内存空间给用户线程使用，因此CMS收集器不能等到老年代几乎完全填满时再收集。可以通过-XX:CMSInitatingOccu-pancyFraction来设置CMS的触发百分比。
3. CMS基于标记-清除算法，该算法在收集结束时会产生大量内存空间碎片。空间碎片过多时，会给对象性分配带来麻烦，可能出现老年代还有大量空间，但是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC。

##### G1收集器

G1是一款面向服务端应用的垃圾收集器，开创了面向局部手机的设计思路和基于Region的内存布局形式。在G1之前，垃圾收集的目标要么是新生代，要么是老年代，或者是整个Java堆。而G1可以面向堆内存任何部分来组成回收集合（Collection Set，简称CSet）进行回收，衡量标准不再是属于哪个分代，而是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1的Mixed GC模式。

G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域(Region)，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间或者老年代空间。收集器能够对扮演不同角色的Region采用不同的策略去处理。Region中还有专门用于存储大对象的Humongous区域。只要大小超过了Region容量一半的对象即可判定为大对象。每个Region大小可以通过参数-XX: G1HeapRegionSize设定，取值范围1MB-32MB，且为2的N次方。对于超过了整个Region容量的超大对象，会存放在N个连续的Humongous Region中。

G1收集器会跟踪各个Region中的垃圾堆积的价值大小，价值即回收所获得的空间大小一级回收所需时间的经验值，然后在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间（XX:MaxGCPauseMills，默认200ms），优先回收价值收益最大的Region，这种使用Region划分内存空间，以及具有优先级的区域回收方式，保证了G1收集器在有限的时间内获取尽可能高的收集效率。

G1收集器的运作过程大致可划分为以下四个步骤：

1. 初始标记：仅标记GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。这个阶段需要停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1在这个阶段没有额外停顿。
2. 并发标记：从GC Roots开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，该阶段耗时较长，但可与用户线程并发执行。对象图扫描完成后，还要重新处理SATB记录下的在并发时有变动的对象。
3. 最终标记：对用户线程做一个短暂暂停，用于处理并发阶段结束后仍遗留下来的少量SATB记录
4. 筛选回收：负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来指定回收计划，可以自由选择多个Region构成回收集，把决定回收 的那部分Region的存活对象复制到空的Region中，再清理掉整个旧Region的 全部空间，这里涉及存活对象的移动，需要暂停用户线程。
